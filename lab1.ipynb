{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPtgHJbyW4uDo69RmxEPgjj"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iFsnureuofwm",
        "outputId": "ebab5820-946d-446f-adb6-fdca80fea138"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'hku_phys3151_2022'...\n",
            "remote: Enumerating objects: 326, done.\u001b[K\n",
            "remote: Counting objects: 100% (34/34), done.\u001b[K\n",
            "remote: Compressing objects: 100% (33/33), done.\u001b[K\n",
            "remote: Total 326 (delta 14), reused 1 (delta 1), pack-reused 292\u001b[K\n",
            "Receiving objects: 100% (326/326), 26.23 MiB | 12.52 MiB/s, done.\n",
            "Resolving deltas: 100% (164/164), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/XiaoxueRan/hku_phys3151_2022"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd h"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wgt6a7yNpcKM",
        "outputId": "df8c5539-d0ce-416c-a944-9a1898c53ec3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34mhku_phys3151_2022\u001b[0m/  \u001b[01;34msample_data\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from pandas import DataFrame"
      ],
      "metadata": {
        "id": "gt4K0qpipcVb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/hku_phys3151_2022/logistic-regression/logistic-regression-example-1.csv\")"
      ],
      "metadata": {
        "id": "FIFkCimppcaz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(pd.concat([df.head(10), df.tail(10)]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mZVGO_GZp7T7",
        "outputId": "b42cec31-5640-4000-9bc3-8a7bf4c469f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
            "0              6      148             72             35        0  33.6   \n",
            "1              1       85             66             29        0  26.6   \n",
            "2              8      183             64              0        0  23.3   \n",
            "3              1       89             66             23       94  28.1   \n",
            "4              0      137             40             35      168  43.1   \n",
            "5              5      116             74              0        0  25.6   \n",
            "6              3       78             50             32       88  31.0   \n",
            "7             10      115              0              0        0  35.3   \n",
            "8              2      197             70             45      543  30.5   \n",
            "9              8      125             96              0        0   0.0   \n",
            "758            1      106             76              0        0  37.5   \n",
            "759            6      190             92              0        0  35.5   \n",
            "760            2       88             58             26       16  28.4   \n",
            "761            9      170             74             31        0  44.0   \n",
            "762            9       89             62              0        0  22.5   \n",
            "763           10      101             76             48      180  32.9   \n",
            "764            2      122             70             27        0  36.8   \n",
            "765            5      121             72             23      112  26.2   \n",
            "766            1      126             60              0        0  30.1   \n",
            "767            1       93             70             31        0  30.4   \n",
            "\n",
            "     DiabetesPedigreeFunction  Age  Outcome  \n",
            "0                       0.627   50        1  \n",
            "1                       0.351   31        0  \n",
            "2                       0.672   32        1  \n",
            "3                       0.167   21        0  \n",
            "4                       2.288   33        1  \n",
            "5                       0.201   30        0  \n",
            "6                       0.248   26        1  \n",
            "7                       0.134   29        0  \n",
            "8                       0.158   53        1  \n",
            "9                       0.232   54        1  \n",
            "758                     0.197   26        0  \n",
            "759                     0.278   66        1  \n",
            "760                     0.766   22        0  \n",
            "761                     0.403   43        1  \n",
            "762                     0.142   33        0  \n",
            "763                     0.171   63        0  \n",
            "764                     0.340   27        0  \n",
            "765                     0.245   30        0  \n",
            "766                     0.349   47        1  \n",
            "767                     0.315   23        0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.optimize import fmin_tnc\n",
        "\n",
        "\n",
        "class LogisticRegressionUsingGD:\n",
        "\n",
        "# Activation function used to map any real value between 0 and 1\n",
        "    @staticmethod\n",
        "    def sigmoid(x):\n",
        "        return 1 / (1 + np.exp(-x))\n",
        "\n",
        "# Computes the weighted sum of inputs Similar to Linear Regression\n",
        "    @staticmethod\n",
        "    def net_input(theta, x):\n",
        "        return np.dot(x, theta)\n",
        "\n",
        "# Calculates the probability that an instance belongs to a particular class\n",
        "    def probability(self, theta, x):\n",
        "        return self.sigmoid(self.net_input(theta, x))\n",
        "\n",
        "# Computes the cost function for all the training samples\n",
        "    def cost_function(self, theta, x, y):\n",
        "        m = x.shape[0]\n",
        "        total_cost = -(1 / m) * np.sum(\n",
        "            y * np.log(self.probability(theta, x)) + (1 - y) * np.log(\n",
        "                1 - self.probability(theta, x)))\n",
        "        return total_cost\n",
        "\n",
        "# Computes the gradient of the cost function at the point theta\n",
        "    def gradient(self, theta, x, y):\n",
        "        m = x.shape[0]\n",
        "        return (1 / m) * np.dot(x.T, self.sigmoid(self.net_input(theta, x)) - y)\n",
        "\n",
        "    def fit(self, x, y, theta):\n",
        "        opt_weights = fmin_tnc(func=self.cost_function, x0=theta, fprime=self.gradient, args=(x, y.flatten()))\n",
        "        self.w_ = opt_weights[0]\n",
        "        return self\n",
        "\n",
        "    def predict(self, x):\n",
        "        theta = self.w_[:, np.newaxis]\n",
        "        return self.probability(theta, x)\n",
        "\n",
        "    def accuracy(self, x, actual_classes, probab_threshold=0.5):\n",
        "        predicted_classes = (self.predict(x) >= probab_threshold).astype(int)\n",
        "        predicted_classes = predicted_classes.flatten()\n",
        "        accuracy = np.mean(predicted_classes == actual_classes)\n",
        "        return accuracy * 100\n"
      ],
      "metadata": {
        "id": "Gb7lRmsgp7Wj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "data = df"
      ],
      "metadata": {
        "id": "ljWoWDeHp7Y7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = data.iloc[:, :-1] # the 8 features we have\n",
        "y = data.iloc[:, -1] # the outcomes"
      ],
      "metadata": {
        "id": "3Ab1Oo95p7bJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X= np.c_[np.ones((X.shape[0], 1)), X]\n",
        "y = y.reshape((len(y), 1))\n",
        "theta = np.zeros((X.shape[1], 1))"
      ],
      "metadata": {
        "id": "_b-jSrLVrOxb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model1 = LogisticRegressionUsingGD()\n",
        "model1.fit(X, y, theta)\n",
        "accurcy = model1.accuracy(X, y.flatten())\n",
        "parameters = model1.w_\n",
        "print(\"the accuracy of the model is {}\".format(accuracy))\n",
        "print(\"the model parameters got by gradient descent: \")\n",
        "print(parameters)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nn2QOVu5rOzz",
        "outputId": "be714b1e-ff37-4c3a-aa85-22bf1237b8a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the accuracy of the model is 0.77734375\n",
            "the model parameters got by gradient descent: \n",
            "[-2.10114341e+00 -2.10114341e+00 -2.10114341e+00 -2.10114341e+00\n",
            "  1.23189622e-01  3.51633461e-02 -1.32951486e-02  6.18424263e-04\n",
            " -1.19160500e-03  8.96999934e-02  9.45173921e-01  1.48662457e-02]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = LogisticRegression() # prebuit package from scikit learn\n",
        "model.fit(X, y)\n",
        "parameters = model.coef_\n",
        "predicted_classes = model.predict(X)\n",
        "accuracy = accuracy_score(y.flatten(), predicted_classes)\n",
        "print(\"the accuracy of the model using scikit learn is {}\".format(accuracy))\n",
        "print(\"the model parameters got by gradient descent: \")\n",
        "print(parameters)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hJiG6gthrO2W",
        "outputId": "117f48c0-bed0-4cb8-e8d0-40389c2c16e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the accuracy of the model using scikit learn is 0.77734375\n",
            "the model parameters got by gradient descent: \n",
            "[[-2.01001934e+00 -2.01001934e+00 -2.01001934e+00  1.10611906e-01\n",
            "   3.39301870e-02 -1.33234591e-02 -1.26806905e-03 -1.02834294e-03\n",
            "   9.11158209e-02  6.79865175e-01  1.60829968e-02]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X1=[[1, 6, 150, 36, 170, 42, 1, 51],\n",
        "    [1, 0, 85, 70, 24, 200, 25, 0.2, 25]]\n",
        "\n",
        "print('the prediction of the first method using model1: ', model1.predict(X1))"
      ],
      "metadata": {
        "id": "gu0QVC4mrO4T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('the prediction of the first method using prebuilt package: ', model.predict(X1))"
      ],
      "metadata": {
        "id": "1LopzLCxuNCF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Rd8ESmFquNEr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}